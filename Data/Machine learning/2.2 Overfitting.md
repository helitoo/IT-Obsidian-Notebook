
```insta-toc
---
title:
  name: Mục lục
  level: 1
  center: false
exclude: ""
style:
  listType: number
omit: []
levels:
  min: 1
  max: 6
---

# Mục lục

1. Hiện tượng overfitting
2. Các tiêu chuẩn đánh giá chất lượng mô hình
    1. Training error
    2. Test error
3. Các kỹ thuật tránh overfitting
    1. Validation
    2. Cross-validation
    3. Regularization
        1. Early stopping
        2. Thêm số hạng vào hàm mất mát
```

# Hiện tượng overfitting

Trong các bài toán [[1.1. Các khái niệm cơ bản trong machine learning#Kinh nghiệm|học có giám sát (Superivised learning)]], mục tiêu của ta là tìm một hàm $f(\mathbf{x})$ sao cho $\mathbf{y}\approx\mathbf{\hat{y}}=f(\mathbf{x})$ và sai số giữa $\mathbf{y}$ và $\mathbf{\hat{y}}$ là thấp nhất (**fit**).

**Overfitting** là hiện tượng mô hình quá khớp trên tập training, nhưng lại sai lệch lớn trên các tập dữ liệu khác. Lúc này, ta nói mô hình thiếu **tính tổng quát (Generalization)**.

![](https://miro.medium.com/1*_7OPgojau8hkiPUiHoGK_w.png)

Khi $\mathbf{\hat{y}}$ có **bậc (số lượng tham số)** càng cao thì độ fit với tập dữ liệu càng cao. Mô hình có bậc càng cao thì ta nói nó càng **phức tạp**.

# Các tiêu chuẩn đánh giá chất lượng mô hình

Một mô hình được coi là tốt (fit) nếu cả training error và test error đều thấp.
- Nếu training error thấp nhưng test error cao, mô hình bị **overfitting**.
- Nếu training error cao và test error cao, mô hình bị **underfitting**. Xác suất để underfitting thường rất nhỏ.
- Nếu training error và test error đều thấp và tương đương nhau, mô hình tốt (**tính phổ quát**).

## Training error

Đại lượng này là **mức độ sai khác giữa đầu ra thực và đầu ra dự đoán của mô hình**, thường là giá trị của hàm mất mát áp dụng lên **training data**. Hàm mất mát này cần có một thừa số $1/N_{train}$ để tính giá trị trung bình, tức mất mát trung bình trên mỗi điểm dữ liệu.

Với các bài toán regression, đại lượng này thường được xác định bởi mean squared error (MSE):
$$\text{training error}=\frac{1}{2N_\text{train}}\sum_\text{training set}\|\mathbf{y}-\mathbf{\hat{y}}\|^2_2$$

## Test error

Tương tự như trên, nhưng mô hình tìm được được áp dụng vào **test data**. Chú ý rằng, khi xây dựng mô hình, ta không được sử dụng thông tin trong tập dữ liệu này.

# Các kỹ thuật tránh overfitting

## Validation

Validation là **trích một phần dữ liệu từ test set (validation set)** để đánh giá. **Validator error** là training error được áp dụng lên validation set. Nếu cả training error và validator error đều nhỏ, có thể ngầm định test error cũng sẽ nhỏ.

Thông thường, ta bắt đầu từ mô hình đơn giản, sau đó tăng dần độ phức tạp của mô hình. Khi độ phức tạp này tăng lên:
- Training error sẽ có xu hướng nhỏ dần.
- Validation error ban đầu thường giảm dần và đến một lúc sẽ tăng lên do overfitting xảy ra.

Để chọn ra một mô hình tốt, ta quan sát validation error. Khi validation error có chiều hướng tăng lên thì ta chọn mô hình trước đó. Kỹ thuật này còn được gọi là [[#Early stopping]].
![](https://www.researchgate.net/publication/371207468/figure/fig5/AS:11431281164191784@1685639498540/llustration-of-the-concept-of-early-stopping-The-model-that-should-be-selected.ppm)

## Cross-validation

Cross-validation là một cải tiến của validation với **kích thước validation set nhỏ** nhưng chất lượng mô hình được đánh giá trên nhiều tập validation khác nhau.

Một cách thường được sử dụng là chia training set ra $k$ tập con không giao nhau, có kích thước gần bằng nhau.
- Tại mỗi lần (**run**), 1 trong số $k$ tập con được lấy ra làm validation set, $k-1$ tập còn lại sẽ dùng làm training set để xây dựng các mô hình khác nhau.
- Mô hình cuối được xác định dựa trên trung bình của các training error và validation error. Cách làm này còn có tên gọi là **k-fold cross-validation**.

Khi $k$ bằng với số lượng phần tử trong training set ban đầu, tức mỗi tập con có đúng một phần tử, ta gọi kỹ thuật này là **leave-one-out**.

## Regularization

Regularization là thay đổi mô hình một chút, chấp nhận **hy sinh training error**, nhưng **giảm độ phức tạp của mô hình**, giúp tránh overfitting trong khi vẫn giữ được tính tổng quát của nó.

Dưới đây là một vài kỹ thuật regularization.

### Early stopping

Rất nhiều các mô hình được xây dựng bằng cách sử dụng các thuật toán lặp cho tới khi hàm mất mát hội tụ để tìm ra nghiệm. Nhìn chung, giá trị hàm mất mát giảm dần khi số vòng lặp tăng lên.

Một giải pháp giúp giảm overfitting là dừng thuật toán trước khi nó hội tụ tên là early stopping. Trong khi huấn luyện, ta tính toán cả training error và validation error, **nếu training error vẫn có xu hướng giảm nhưng validation error có xu hướng tăng** thì ta dừng thuật toán.

### Thêm số hạng vào hàm mất mát

Số hạng này thường dùng để đánh giá độ phức tạp của mô hình với giá trị lớn thể hiện mô hình phức tạp. Hàm mất mát mới này được gọi là **regularized loss function**, thường được định nghĩa như sau:
$$\mathcal{L}_{reg}(\theta)=\mathcal{L}(\theta)+\lambda R(0)$$
Trong đó:
- $R(\theta)$ là **số hạng regularization**, chỉ phụ thuộc vào $\theta$.
- $\lambda$ là **tham số regularization**, thường là một số dương nhỏ, càng gần 0 thì càng gần với nghiệm của $\mathcal{L}(\theta)$.

Có 2 số hạng regularization thường dùng là norm $l_1$ và $l_2$.





















