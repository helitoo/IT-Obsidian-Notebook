
Bài đọc trước: [[1. Đại số tuyến tính (Linear algebra) và Numpy]].
```insta-toc
---
title:
  name: Mục lục
  level: 1
  center: false
exclude: ""
style:
  listType: number
omit: []
levels:
  min: 1
  max: 6
---

# Mục lục

1. Xác suất (Probability)
    1. Biến ngẫu nhiên (Random variable)
    2. Xác suất đồng thời (Joint probability)
    3. Xác suất có điều kiện (Conditional probability)
    4. Biến ngẫu nhiên độc lập (Independent)
    5. Các tham số của biến ngẫu nhiên
        1. Kỳ vọng (Expectation)
        2. Các tham số khác
2. Một số hàm phân phối xác suất (Probability distribution)
    1. Phân phối Bernouli (Binoumial) và Phân phối Categorical
    2. Phân phối Beta và Phân phối Dirichlet
    3. Phân phối chuẩn (Normal)
3. Thống kê suy diễn (Inferential statistics)
    1. Maximum likelihood estimation (MLE)
    2. Maximum a Posteriori (MAP)
```

# Xác suất (Probability)

## Biến ngẫu nhiên (Random variable)

Biến ngẫu nhiên $x$ là một đại lượng dùng để đo những đại lượng không xác định. Biến này có thể được dùng để ký hiệu kết quả / đầu ra (outcome) của một thí nghiệm. Khi chúng ta quan sát những thí nghiệm này nhiều lần thì sẽ thu được nhiều kết quả $x_i$ tương ứng khác nhau, nhưng số lần xuất hiện của các kết quả có thể sẽ khác nhau và xác suất của chúng được đo bằng **hàm phân phối xác suất (Probability distribution, CDF)** $p(x)$.

Biến ngẫu nhiên có 2 loại:
1. **Biến ngẫu nhiên rời rạc (Discere)**: Khi $x$ có nhiều giá trị cụ thể, khi đó:
$$\sum p(x) = 1$$

2. **Biến ngẫu nhiên liên tục (Continuous)**: Khi $x$ không có giá trị cụ thể mà chỉ có thể ước lượng một giá trị trong khoảng bao nhiêu, cho nên $p(x_i) = 0$. Để đo xác suất tại một khoảng giá trị từ $a$ đến $b$, ta dùng **hàm mật độ xác suất (Probability density function, PDF) $f(x)$**:
$$f(a \leq x \leq b) =  \int_a^b p(x)dx \quad ; \quad \int_{-\infty}^\infty p(x)dx = 1$$

## Xác suất đồng thời (Joint probability)

Khi có nhiều biến ngẫu nhiên $X_i$ được quan sát đồng thời, ta có thể viết dưới dạng vector $X = [x_1; x_2; ...; x_n]$. Xác suất để xảy ra một tổ hợp bất kỳ là $p(x_1 = a; \quad x_2 = b; \quad ...; \quad x_n = z)$.

Xác suất đồng thời cũng được phân loại là ngẫu nhiên và liên tục.

**Xác suất biên (Marginal probability)**: Là xác suất của từng biến ngẫu nhiên trong tập các biến ngẫu nhiên.
Xét riêng $X = [x; y]$.
- Nếu $X$ rời rạc:
$$p(x_i) = \sum_{x_i} p(x_1, x_2, ..., x_n)$$
- Nếu $X$ liên tục:
$$p(x_i) = \int p(x_1, x_2, ..., x_n).dx_1.dx_2...$$

## Xác suất có điều kiện (Conditional probability)

Xác suất để một biến ngẫu nhiên $x$ nhận một giá trị nào đó biết rằng biến ngẫu nhiên $y$ có giá trị $y^*$ được gọi là xác suất có điều kiện:
$$p(x \mid y = y^*) = \frac{p(x, y = y^*)}{p(y = y^*)}
;\quad
p(x \mid y) = \frac{p(x, y)}{p(y)}
$$

Biến đổi, ta có:
$$p(x,y)=p(x \mid y).p(y)=p(y \mid x).p(x)$$
Tương tự với trường hợp nhiều biến:
$$p(x_1, x_2, ..., x_n) = p(x_1 \mid x_2, x_3, x_4, ...).p(x_2 \mid x_3, x_4, ...)...$$

**Công thức Bayes**: Tiếp tục biến đổi công thức trên:
$$p(y \mid x) = \frac{p(x \mid y).p(y)}{p(x)}
= \frac{p(x \mid y).p(y)}{\sum_y p(x,y)}
= \frac{p(x \mid y).p(y)}{\sum_y (p(x \mid y).p(y))}
$$

## Biến ngẫu nhiên độc lập (Independent)

Nếu giá trị của biến $x$ không có nhiều ý nghĩa giúp ta suy ra giá trị của biến $y$, thì $x$ và $y$ độc lập. Khi đó:
$$p(x \mid y) = p(x); \quad p(y \mid x) = p(y); \quad p(x,y) = p(x).p(y)$$

## Các tham số của biến ngẫu nhiên

### Kỳ vọng (Expectation)

Kỳ vọng của biến ngẫu nhiên $x$ là giá trị trung bình xuất hiện trong mẫu:
$$E[x] = \sum_x p(x).x;\quad E[x] = \int_{-\infty}^{\infty} p(x).x.dx$$

Ở đây, $p(x)$ được hiểu là trọng số của biến ngẫu nhiên $x_i$. Một cách tổng quát, ta có thể truyền một hàm trọng số $f(x)$ bất kỳ vào hàm kỳ vọng:
$$E[f(x)] = \sum_x f(x).x$$
Tương tự với biến liên tục.

Tính chất:
1. Kỳ vọng của hằng số $\alpha$ theo $x$ chính là hằng số đó: $E[\alpha] = \alpha$.
2. Kỳ vọng có tính tuyến tính: $E[\alpha x] = \alpha.E[x]; \quad E[x + y] = E[x] + E[y]$.
3. Nếu 2 biến ngẫu nhiên độc lập thì: $E[xy] = E[x].E[y]$.

### Các tham số khác

Cho một bộ giá trị $x = [x_1, x_2, ..., x_N]$.

- **Kỳ vọng (Expectation)** là trung bình cộng của toàn bộ các giá trị.
$$\overline{x} = \frac{1}{N}.\sum x = \frac{1}{N}.x.\mathbf{1}$$

- **Phương sai (Varience)** là trung bình cộng của bình phương khoảng cách từ mỗi điểm tới kỳ vọng. Phương sai càng nhỏ thì các điểm dữ liệu càng gần với kỳ vọng, tức các điểm dữ liệu càng giống nhau, hay dữ liệu có **tính tập trung**, ngược lại là có **tính phân tán**.
$$\sigma^2 = \frac{1}{N}.\sum (x_i - \overline{x})^2$$

- **Độ lệch chuẩn (Standard deviation)**: Là căn bậc 2 của phương sai ($\sigma$).

- **Hiệp phương sai (Covariance)**: Thể hiện sự tương quan giữa 2 biến $x$ và $y$:
	- $\text{Cov}(x, y) > 0$: 2 biến cùng tăng / giảm.
	- $\text{Cov}(x, y) < 0$: 1 biến tăng, 1 biến giảm.
	- $\text{Cov}(x, y) = 0$: 2 biến không có quan hệ tuyến tính. Khi hiệp phương sai càng gần 1 thì 2 biến có tương quan càng mạnh.

Nếu bộ giá trị $x$ là tập các vector cột, $x_i \in \mathbb{R}^m$, **vector kỳ vọng** và **ma trận hiệp phương sai** được tính bằng:
$$
\overline{X} = \frac{1}{N}.\sum x_i; \quad S = \frac{1}{N}.\hat{X}.\hat{X}^T \in \mathbb{S}^m; \quad \hat{X} = x_i - \overline{x}
$$

Đối với biến liên tục, kỳ vọng và vector kỳ vọng đều có thể được ký hiệu $\mu$.

Tính chất của ma trận hiệp phương sai:
1. Là ma trận đối xứng.
2. Là ma trận nửa xác định dương.
3. Các phần tử trên đường chéo không âm. Chúng là phương sai của từng chiều dữ liệu.
4. Các phần tử ngoài đường chéo là hiệp phương sai giữa thành phần thứ $i$ và $j$ trong bộ dữ liệu.

# Một số hàm phân phối xác suất (Probability distribution)

## Phân phối Bernouli (Binoumial) và Phân phối Categorical

**Phân phối Bernouli** mô tả biến rời rạc $x$ chỉ nhận 2 giá trị tương ứng với $\lambda = [0, 1]$ là xác suất xảy ra từng giá trị đó, $\lambda_i = p(x = x_i)$.

Ký hiệu:
$$p(x = x_i) = \text{Bern}_x[\lambda] = \lambda^{x_i}.(1 - \lambda)^{1-x_i}$$


**Phân phối Categorical** là dạng tổng quát của Bernouli, biến $x$ sẽ nhận một tập giá trị $x = [x_1, x_2, ..., x_K]$ tương ứng với tập tham số $\lambda = [\lambda_1, \lambda_2,..., \lambda_K]$. Tổng các $\lambda$ là 1.

Ký hiệu:
$$p(x = x_i) = \text{Cat}_x[\lambda_i] = \prod_{i=1}^K \lambda_i^{\mathbf{1}[x=x_i]} $$
Với $\mathbf{1}(x=x_i)$ là hàm chỉ báo, trả về $1$ nếu $x = x_i$, $0$ nếu $x \neq x_i$.

Nếu thay vì biểu diễn đầu ra là một số, ta biểu diễn đầu ra là một vector $x_i$ $X = [x_1; x_2; ...; x_K]$ là ma trận đơn vị cấp $K$, vector $x_i$ là **one-hot**, khi đó:
$$p(x = x_i) = \lambda_i = \prod_{i=1}^K \lambda_i^{x_i} $$

## Phân phối Beta và Phân phối Dirichlet

**Phân phối Beta** mô tả biến rời rạc $\lambda \in [0, 1]$, tức là sự biến động của phân phối Bernouli, hay khảo sát khả năng một giá trị $x_i$ xuất hiện.

Ký hiệu:
$$p(\lambda = \lambda_i) = \text{Beta}_\lambda[\alpha, \beta] =
\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) . \Gamma(\beta)}
.\lambda_i^{\alpha-1}
.(1-\lambda)^{\beta-1}
$$

Với:
- $\alpha$ và $\beta$ được gọi là **tham số hình dạng (Shape parameters)**, $\alpha$ là một số thắng, $\beta$ là một số thua.
	- Nếu $\alpha > \beta$, phân phối lệch về phía 1.
	- Nếu $\alpha < \beta$, phân phối lệch về phía 0.
	- Nếu $\alpha = \beta = 1$, phân phối đều (**Uniform distribution**).
	- Nếu $\alpha, \beta > 1$, phân phối tập trung quanh giá trị trung bình.
	- Nếu $\alpha, \beta < 1$, phân phối tập trung ở 0 và 1.
- Hàm gamma:
$$\Gamma(z) = \int_0^\infty t^{z-1}.\exp(-t).dt$$

Một số trường hợp của phân phối Beta:
![](https://i0.wp.com/statisticsbyjim.com/wp-content/uploads/2022/05/beta_distribution_examples.png?w=576&ssl=1)

**Phân phối Diriclet** mô tả biến rời rạc $\lambda \in [\lambda_1, \lambda_2,..., \lambda_K]$, tức là sự biến động của phân phối Categorical.

Ký hiệu:
$$p(\lambda_1 ... \lambda_K) = \text{Dir}_{\lambda_1 ... \lambda_K}[\alpha_1, ..., \alpha_K] =
\frac{\Gamma(\sum_{k=1}^K \alpha_k)}{\prod_{k=1}^K \Gamma(\alpha_k)}
.\prod_{k=1}^K \lambda_k^{\alpha_k-1}
$$

## Phân phối chuẩn (Normal)

**Phân phối chuẩn một chiều (Univariate normal, Gaussian distribution)** mô tả các biến liên tục, có 2 tham số là kỳ vọng $\mu$ và phương sai $\sigma^2$.
- Giá trị $\mu$ có thể là bất kỳ số thực nào, thể hiện vị trí của giá trị mà tại đó mà hàm mật độ xác suất đạt giá trị cao nhất.
- Giá trị $\sigma^2$ là một giá trị dương, với $\sigma$ thể hiện độ rộng của phân phối này. $\sigma$ lớn chứng tỏ khoảng giá trị đầu ra có khoảng biến đổi mạnh, và ngược lại.

Ký hiệu:
$$p(x)
=\text{Norm}_x[\mu, \sigma^2]
=\mathcal{N}(\mu, \sigma^2)
= \frac{1}{\sqrt{2 \pi \sigma^2}}.\exp \left( -\frac{(x - \mu)^2}{2 \sigma^2} \right)
$$

Với $e^x$ có thể được viết gọn thành $\exp{x}$.

Tổng quát hóa lên dạng **nhiều chiều (Bivariate normal distribution)** khi:
- Tham số $\mu \in \mathbb{R}^D$ nhận vector kỳ vọng.
- Tham số $\sigma^2  \in \mathbb{S}^D$ nhận ma trận hiệp phương sai, ký hiệu mới là $\Sigma$.

Khi đó:
$$p(x)
=\text{Norm}_x[\mu, \Sigma^2]
=\mathcal{N}(\mu, \Sigma^2)
= \frac{1}{\sqrt{(2 \pi)^\frac{D}{2} (\det\Sigma)^\frac{1}{2}}}.
\exp\left( \frac{1}{2}.(x - \mu)^T.\Sigma^{-1}.(x - \mu) \right)
$$

# Thống kê suy diễn (Inferential statistics)

Có rất nhiều mô hình machine learning được xây dựng dựa trên các **mô hình thống kê (Statistical models)**. Các mô hình thống kê thường dựa trên các phân phối xác suất như trên.

Với một mô hình thông kê bất kỳ, ký hiệu $\theta$ là tập hợp tất cả các tham số của mô hình đó. "Learning" chính là quá trình ước lượng (estimate) bộ tham số $\theta$ sao cho mô hình tìm được khớp với phân phối của dữ liệu nhất. Quá trình này còn được gọi là **ước lượng tham số (Parameter estimation)**.

Nói cách khác, với một bộ dữ liệu cho trước phù hợp với một phân phối xác suất cho trước, **thống kê suy diễn** là suy đoán bộ tham số $\theta$ của phân phối đó sao cho phù hợp với bộ dữ liệu đó.

## Maximum likelihood estimation (MLE)

Cho một tập dữ liệu $x = [x_1, x_2, ..., x_N]$, phương pháp MLE là tìm $\theta$ thỏa mãn:
$$\theta = \arg\max_\theta p(x_1, x_2,...,x_N \mid \theta)$$
Ở đây, $\arg\max$ được hiểu như $\max$.

Ta có $p(x_1, x_2,...,x_N \mid \theta)$ chính là xác suất để toàn bộ các sự kiện $x_i$ đồng thời xảy ra khi $\theta$ xảy ra, xác suất này còn được gọi là **likelihood**. Để cho $\theta$ cao nhất có thể, ta cần tìm max của likelihood.

Giả sử các điểm dữ liệu $x_i$ là độc lập, likelihood có thể được xấp xỉ như sau:
$$p(x_1, x_2,...,x_N \mid \theta)
\approx \prod_{n=1}^N p(x_n \mid \theta)
\Rightarrow 
\log \left( \prod_{n=1}^N p(x_n \mid \theta) \right)
= \sum_{n=1}^N \log{p(x_n \mid \theta)}
$$

Do đó:
$$\theta
= \arg\max_\theta \prod_{n=1}^N p(x_n \mid \theta)
= \arg\max_\theta \sum_{n=1}^N \log{p(x_n \mid \theta)}
$$

Chú thích thêm về công thức tổng (**log-likelihood**):
- $\log(A.B) = \log(A) + \log(B)$.
- Logarithm là một hàm đồng biến, nên một biểu thức dương sẽ là max nếu log là max.

**VD**: Giả sử tung một đồng xu $N$ lần và nhận được $n$ mặt ngửa. Tìm xác suất $\lambda$ xuất hiện mặt ngửa.

Gọi chuỗi phép thử Bernouli trả về lần lượt các giá trị $x = [x_1, x_2, ..., x_N]$, trong đó có $n$ lần $x_i$ là ngửa, hay ta quy ước là bằng $1$. Suy ra:
$$\sum_{n=1}^N x_i = n; \quad N - \sum_{n=1}^N = N - n = m; \quad
p_\lambda(x_i) = p(x_i \mid \lambda) = \lambda^{x_i}.(1 - \lambda)^{1-x_i}$$

Giả sử có sự độc lập giữa khả năng xuất hiện mặt ngửa và sấp:
$$
\begin{align}
	\lambda = \arg\max_\lambda{p(x_1, x_2,...,x_N \mid \lambda)}
	& = \arg\max_\lambda{\prod_{i=1}^N p(x_i \mid \lambda)}
	= \arg\max_\lambda{\prod_{i=1}^N \left(\lambda^{x_i}.(1 - \lambda)^{1-x_i} \right)}\\
	& = \arg\max_\lambda \left( \lambda^n.(1-\lambda)^m \right)\\
	& = \arg\max_\lambda (n.\log(\lambda) + m.\log(1 - \lambda))
\end{align}
$$

Biến đổi một chút, ta thấy $\lambda = \frac{n}{N}$.

**VD**: Giả sử tung 1 viên xúc sắc có 6 mặt có xác suất rơi vào các mặt có thể không đều nhau. Giả sử trong $N$ lần tung, số lượng xuất hiện các mặt thứ nhất, thứ hai,. . . , thứ sáu lần lượt là $n_1, n_2,..., n_6$, với $\sum_{i=1}^6 n_i = N$ và $n_i > 0$. Tính xác suất rơi vào mỗi mặt của xúc sắc.

Ta có thể đưa đầu ra về các vector one-hot $x_i$. Trong đó, phần tử 1 của vector $x_i$ chính là $n_i$.

Khi đó, tuân theo phân phối Categorical:
$$p_\lambda(x_i)=p(x_i \mid \lambda ) = \prod_{j=1}^6 \lambda_j^{x_j}$$

Giả sử có sự độc lập giữa khả năng xuất hiện các mặt của xúc sắc:
$$
\begin{align}
	\lambda
	& = \arg\max_\lambda \left( \prod_{i=1}^N p(x_i \mid \lambda) \right)
	= \arg\max_\lambda \left( \prod_{i=1}^N \prod_{j=1}^6 \lambda_j^{x_j} \right) \\
	& = \arg\max_\lambda \left( \prod_{j=1}^6 \lambda_j^{n_j} \right)
	= \arg\max_\lambda \left( \sum_{j=1}^6 n_j \log(\lambda_j) \right)
\end{align}
$$

Áp dụng phương pháp nhân tử Larrange có thể thu được nghiệm $\lambda_i = \frac{n_i}{N}$.

**VD**: Khi thực hiện một phép đo, giả sử rằng rất khó để có thể đo chính xác độ dài của một vật. Thay vào đó, người ta thường đo vật đó nhiều lần rồi suy ra kết quả, với giả thiết rằng các phép đo là độc lập với nhau và kết quả mỗi phép đo là một phân phối chuẩn. Ước lượng chiều dài của vật đó dựa trên các kết quả đo được.

Chiều dài của vật có thể được coi là g**iá trị mà hàm mật độ xác suất đạt giá trị cao nhất**, tức khả năng rơi vào khoảng giá trị xung quanh nó là lớn nhất.

Trong phân phối chuẩn, ta biết rằng hàm mật độ xác suất **đạt giá trị lớn nhất tại kỳ vọng** của phân phối đó. Chú ý rằng kỳ vọng của phân phối và kỳ vọng của dữ liệu quan sát được có thể không chính xác bằng nhau, nhưng rất gần nhau.

Như ta đã biết công thức hàm phân phối xác suất chuẩn một chiều như sau:

$$p(x_i \mid \mu,\sigma^2)
= \frac{1}{\sqrt{2 \pi \sigma^2}}.\exp \left( -\frac{(x_i - \mu)^2}{2 \sigma^2} \right)
$$

Giả thiết rằng kết quả các phép đo là độc lập:
$$\mu, \sigma = \arg\max_{\mu, \sigma} \left( \prod_{i=1}^N p(x_i \mid \mu, \sigma^2) \right)
= \arg\max_{\mu, \sigma} \left( - N \log(\sigma) - \frac{\sum_{i=1}^N (x_i - \mu)^2}{2\sigma^2} \triangleq J(\mu, \sigma) \right)
$$
Chú ý rằng phần hằng số $2\pi$ đã được lược bỏ vì nó không ảnh hưởng đến kết quả.

Để tìm $\mu$ và $\sigma$, ta giải phương trình Jacobi $J(\mu, \sigma)$ và thu được kết quả:
$$
\mu = \frac{\sum_{i=1}^N x_i}{N}; \quad
\sigma^2 = \frac{\sum_{i=1}^N (x_i - \mu)^2}{N}
$$

## Maximum a Posteriori (MAP)

Khi tập dữ liệu ban đầu quá nhỏ (**low-training**), việc sử dụng MLE là không đáng tin cậy. Lúc này, ta cần dùng phương pháp MAP.

Trong MAP, chúng ta cần một giả thiết $p(\theta)$ biết trước gọi là **prior** của tham số $\theta$. Từ giả thiết này, chúng ta có thể suy ra các khoảng giá trị và phân bố của tham số.
$$
\begin{align}
\theta
= \arg\max_\theta p(\theta \mid x_1, x_2, ..., x_n)
&= \arg\max_\theta \frac{p(x_1, x_2, ..., x_n \mid \theta).p(\theta)}{p(x_1, x_2, ..., x_n)}\\
&= \arg\max_\theta (p(x_1, x_2, ..., x_n \mid \theta).p(\theta))\\
&= \arg\max_\theta \left( \prod_{i=1}^N (p(x_i \mid \theta).p(\theta)) \right)

\end{align}
$$

Trong đó:
- $p(x_1, x_2, ..., x_n \mid \theta)$ được gọi là likelihood.
- $p(\theta \mid x_1, x_2, ..., x_n)$ được gọi là posterior.
- $p(\theta)$ được gọi là prior.

Như vậy, điểm khác biệt lớn nhất giữa MLE và MAP là việc hàm mục tiêu của MAP có thêm prior. Ta kết luận rằng posterior tỉ lệ thuận với tích của likelihood và prior.

**Conjugate prior**: Nếu posterior và prior có chung dạng thì cả 2 được gọi là conjugate prior. Lúc đó:
- Nghiệm của MLE và MAP là như nhau.
- Prior được gọi là conjugate của posterior.

Một số cặp conjugate:
- Phân phối **Beta** là conjugate của phân phối **Bernoulli**.
- Phân phối **Dirichlet** là conjugate của phân phối **Categorical**.
- Nếu likelihood là một **Gaussian** và prior cho vector kỳ vọng của nó cũng là **Gaussian** thì posterior cũng là một **Gaussian**. Ta nói rằng Gaussian đã conjugate với chính nó.
- Nếu likelihood là một **Gaussian** và prior cho phương sai tuân theo phân phối **Gamma** thì posterior là một **Gaussian**. Ta nói rằng phương sai Gamma đã conjugate với Gaussian.

VD:
Xét hàm mật độ xác suất của phân phối Bernouli và phân phối Beta:
$$p(x_i \mid \lambda) = \lambda^{x_i}.(1 - \lambda)^{1-x_i}; \quad p(\lambda)=\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) . \Gamma(\beta)}
.\lambda_i^{\alpha-1}
.(1-\lambda)^{\beta-1}$$

Bỏ qua phần hàm Gamma giúp chuẩn hóa hàm mật độ xác suất, ta thấy phân phối Bernouli có cùng họ với Beta. Cụ thể, nếu sử dụng phân phối Beta làm prior cho tham số $\lambda$, và bỏ qua phần thừa số hằng số, posterior sẽ có dạng:
$$p(\lambda \mid x) \quad\propto\quad p(x \mid \lambda).p(\lambda) \quad\propto\quad \lambda^{x+\alpha-1}.(1-\alpha)^{1-x+\beta-1}$$
Ký hiệu $\propto$ nghĩa là "tỷ lệ với".

Ta thấy ở biến đổi cuối cùng, posterior cũng có dạng là một phân phối Bernouli. Nên phân phối Beta được gọi là conjugate của Bernouli.

Lúc này, $\alpha$ và $\beta$ có thể được gọi là **siêu tham số (Hyperparameter)**.

Giả sử tung một đồng xu $N$ lần và nhận được $n$ mặt ngửa, nếu áp dụng phương pháp MAP, ta thu được:
$$
\begin{align}
\lambda &= \arg\max_{\lambda} \left[ p(x_1, \ldots, x_N \mid \lambda)\, p(\lambda) \right] \\
&= \arg\max_{\lambda} \left[ \left( \prod_{i=1}^N \lambda^{x_i} (1-\lambda)^{1-x_i} \right) 
\lambda^{\alpha-1} (1-\lambda)^{\beta-1} \right] \\
&= \arg\max_{\lambda} \left[ \lambda^{n+\alpha - 1} (1-\lambda)^{m+\beta - 1} \right]\\
\Rightarrow \lambda &= \frac{n + \alpha - 1}{N + \alpha + \beta - 2}
\end{align}
$$

Việc hiệu chỉnh các giá trị $\alpha$ và $\beta$, nhất là khi $\alpha = \beta = 1$, sẽ cho ra các kết quả khác nhau, đây là khoảng giá trị ước lượng của MAP.
