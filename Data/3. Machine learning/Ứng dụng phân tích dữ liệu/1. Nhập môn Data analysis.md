
```insta-toc
---
title:
  name: Mục lục
  level: 1
  center: false
exclude: ""
style:
  listType: number
omit: []
levels:
  min: 1
  max: 6
---

# Mục lục

1. Tổng quan
2. Các bước phân tích dữ liệu
    1. Define the problems / Make the questions
    2. Collect and Clean the data
    3. Perform Data analysis
    4. Report the findings
```

# Tổng quan

*Phân tích dữ liệu* là dựa vào những dữ liệu sẵn có, tìm ra ý nghĩa của chúng, thông qua đó đưa ra các dự đoán về các sự kiện trong tương lai (**insight**), hỗ trợ đưa ra quyết định.

>[!note]
>Phân tích dữ liệu không phải là đưa ra các dự báo chính xác tuyệt đối, mà chỉ làm *giảm sự phỏng đoán (**Guesswork**), tăng độ chính xác*.

# Các bước phân tích dữ liệu

>[!note]
>Phân tích dữ liệu là một quy trình gồm nhiều bước thực hiện và có nhiều cách để đi, **tùy vào tình hình thực tế mà bạn có bước đi phù hợp**.

## Define the problems / Make the questions

Xác định vấn đề cần giải quyết.

## Collect and Clean the data

Thu thập dữ liệu từ nhiều nguồn khác nhau, đồng thời xử lý và làm sạch nó thông qua [[6. Nhập môn data pipelining|data pipeline]].

Phân loại dữ liệu theo nội dung:
1. **Quantitative (Numeric)**: Dữ liệu định lượng.
2. **Quanlitative (Descriptative)**: Dữ liệu định tính.

Phân loại dữ liệu theo cấu trúc:
1. **Structured**: Có metadata, schema,... Trong đó, dữ liệu được chia thành nhiều hàng, mỗi hàng được chia thành nhiều thuộc tính (bảng).
2. **Unstructured**: Ngược lại với structured.
3. **Semi-structured**: Có tính *tự mô tả (Self-description)*, tức là không có metadata, không có structure,... nhưng vẫn đảm bảo cho người dùng đọc hiểu nội dung của nó. VD: *CSV, JSON, XML, MongoDB,...*

Phân loại nguồn dữ liệu:
1. **First-party**: Dữ liệu cục bộ trong tổ chức của bạn.
2. **Second-party**: Dữ liệu trong các tổ chức khác, không được công khai.
3. **Third-party**: Dữ liệu trong các tổ chức khác, được công khai. VD: *REF, Kaggle, RoboFlow, HuggingFace,...*

Phân loại phương pháp thu thập dữ liệu:
1. **Web API**: Dùng API được cung cấp bởi các nguồn dữ liệu.
2. **Web crawling - Web crapping**: Phân tích mã HTML của trang web để lấy về các dữ liệu cần thiết.
3. **Tải dữ liệu về dưới dạng các file**.
4. ...


**Exploratory data analysis - EDA**: Phân tích tổng quan về dữ liệu (*Summary*), kết hợp với sửa chữa dữ liệu, thông qua các công cụ như *Pandas, Data Ladder, Excel, OpenRefine,...*

## Perform Data analysis

Dựa vào những dữ liệu đã có để đưa ra những dự đoán, phỏng đoán.

Các câu hỏi cần trả lời khi phân tích dữ liệu:
1. **Descriptive**: Chuyện gì đã xảy ra trong quá khứ? **Anomalies**: Những điểm dữ liệu bất thường là gì?
2. **Diagnostic**: Tại sao chúng lại xảy ra?
3. **Predictive**: Chuyện gì *có thể* sẽ xảy ra trong tương lai, dự đoán thông qua trending, seasonality,... [[1. Các khái niệm cơ bản trong machine learning|Machine learning / Data model]] là một phần quan trọng của predictive.
4. **Prescriptive**: Nên có những hành động, kế hoạch gì trong tương lai?

Các kỹ thuật dùng trong phân tích dữ liệu:
1. **Aggregation**: Sử dụng các thuật toán thống kê như tính tổng, tính trung bình, đếm số lượng,...
2. **Mining**: Dựa vào các cơ sở Toán học để tìm ra xu hướng của dữ liệu, ý nghĩa của dữ liệu.
3. **Visualization**: Trực quan hóa dữ liệu, tức là biểu diễn dữ liệu thông qua các biểu đồ phù hợp, cô đọng.

## Report the findings

Báo cáo kết quả.

Tiêu chuẩn của bản báo cáo:
- Trực quan, cô đọng.
- Rõ ràng, minh bạch.



















