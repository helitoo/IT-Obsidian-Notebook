
**Tài liệu tham khảo**:
- https://scikit-learn.org/stable/modules/cross_validation.html.
- https://inria.github.io/scikit-learn-mooc/overfit/overfit_module_intro.html.
- Machine Learning cơ bản, Vũ Hữu Tiệp, 2018.

```insta-toc
---
title:
  name: Mục lục
  level: 1
  center: false
exclude: ""
style:
  listType: number
omit: []
levels:
  min: 1
  max: 6
---

# Mục lục

1. Tình huống
2. Nhận biết overfiting / underfiting
    1. Độ phức tạp của model
    2. Kích thước dataset
    3. Đặc thù của model
3. Khảo sát chất lượng model bằng Cross-validation estimation
    1. Cross-validation iterators
    2. sklearn.modelselection.crossvalidate
```

# Tình huống

- **Overfiting**: Là hiện tượng model quá khớp với training set (error cực thấp) trong khi đạt error cao khi gặp phải những dữ liệu nằm ngoài training set. Các model này thường có một lượng lớn tham số, tức là model rất phức tạp.
- **Underfiting**: Là trường hợp ngược lại với overfitting, model cho ra kết quả dường như chẳng khớp gì với training set.

Cả overfiting và underfiting đều không phải hiện tượng tốt tốt.

>[!quote]
>**Error** quá nhỏ hoặc quá lớn **đều là vấn đề**.

3 biểu đồ dưới đây thể hiện bài toán *Regression* với mô hình tương ứng với 3 bậc khác nhau:
- *Mô hình bậc 4*: Khớp nhất so với mô hình kỳ vọng (true function).
- *Mô hình bậc 15*: Overfiting, khớp hoàn toàn với training set và sai lệch hẳn so với true function.
- *Mô hình bậc 1*: Underfiting, dường như không khớp gì với training set và sai lệch hẳn so với true function.

![](https://scikit-learn.org/stable/_images/sphx_glr_plot_underfitting_overfitting_001.png)

Hiện tượng overfit và underfit dẫn đến 2 hiện tượng khác:
- **Variance**: Xảy ra khi overfit. Nếu model quá fit với training set thì khi tiếp cận với dataset mới, model sẽ phán đoán sai, nhưng nhìn chung thì **ở mỗi dataset thì model phán đoán gần như khác hẳn với các dataset khác**.
- **Bias**: Xảy ra khi Underfit. Nếu model không catch được training set thì khi tiếp cận với dataset mới, model sẽ phán đoán sai, nhưng nhìn chung thì **ở mỗi dataset thì model phán đoán gần giống như nhau**.

2 biểu đồ bên dưới thể hiện 2 hiện tượng variance và bias, với mỗi điểm khác nhau trên hình tròn đại diện cho 1 dataset khác nhau, rơi vào các mốc error khác nhau (*tại tâm thì error = 0*).

| ![](variance.png) | ![](bias.png) |
| ----------------- | ------------- |

# Nhận biết overfiting / underfiting

## Độ phức tạp của model

- **Overfit**: Training error rất thấp nhưng testing error rất cao.
- **Underfit**: Training error và testing error đều cao.

>[!quote]
>Model đạt mức tốt nhất tại vị trí mà **training error và testing error đều thấp**.

![](training-testing-error.png)

## Kích thước dataset

Kích thước dataset càng cao thì **training error và testing error sẽ cùng hội tụ về một mức error cố định**, không thể thay đổi thêm dù có tăng kích thước dataset như thế nào đi nữa.

Mốc error này gọi là **Bayes error rate**. Bayes error rate không thể là $0$ vì các lý do như noises, limiting sample size,...

![](varying-sample-size.png)

## Đặc thù của model

Các model khác nhau cho ra kết quả khác nhau, nếu không hiểu rõ về bản chất của model, ta có thể nhầm lẫn rằng model này overfit hoặc underfit hơn model kia.

VD 2 biểu đồ dưới thể hiện polynomial model (trông khá fit với dữ liệu) và decision tree model (có vẻ như overfit).

![](differences-model-families.png)

# Khảo sát chất lượng model bằng Cross-validation estimation

Nhìn chung thì các phương pháp đánh giá model như trên đều dựa trên training error và testing error. **Cross-validation** là phương pháp đánh giá model dựa trên nguyên lý đó. Có rất nhiều cách thực hiện cross-validation, nhưng đều trải qua một số bước như sau:
1. Xáo trộn ngẫu nhiên toàn bộ dataset.
2. Chia dataset thành training set và testing set.
3. Training model bằng training set.
4. Kiểm tra error bằng testing set.

## Cross-validation iterators

Các phương thức sau có chức năng phân chia dataset, đều trả về danh sách các tuple, mỗi tuple có dạng `(training_set, testing_set)`.

**`sklearn.model_selection.KFold(n_splits=5, shuffle=False, random_state=None)`**:
- Chia full dataset thành `n_splits` phần bằng nhau (*sample / fold*).
- Trong đó có 1 phần là testing dataset, còn lại là training dataset.

**`sklearn.model_selection.StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)`**:
- (Repeated) K-Folds có 1 nhược điểm chí mạng đó là các dataset được sinh ra có thể *sẽ không bao chứa các class ít xuất hiện trong dataset gốc*.
- Stratified K-folds là một cải tiến sao cho *tần suất mỗi class trong dataset gốc sẽ được bảo toàn trong dataset được sinh ra*.

**`sklearn.model_selection.RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)`**:
- Lặp đi lặp lại `KFold` `n_repeats` lần.
- Tương tự với `RepeatedStratifiedKFold`.

**`sklearn.model_selection.ShuffleSplit(n_splits=10, test_size=None, train_size=None, random_state=None)`**:
- Có thể coi là dạng mở rộng của repeated K-folds, mỗi lần lặp có thể trùng với lần trước đó (*overlap*).
- Các tham số
	- `n_splits`: Số lần lặp.
	- `test_size`: Tỷ lệ kích thước testing dataset (`float`) hoặc kích thước testing dataset (`int`). Tương tự với `train_size`.
- Tương tự với `StratifiedShuffleSplit`.

**`sklearn.model_selection.LeaveOneOut()` (LOO)**:
- Testing set luôn chỉ có 1 phần tử, còn lại là training set.

**`sklearn.model_selection.LeavePOut(p)` (LPO)**:
- Testing set luôn chỉ có `p` phần tử, còn lại là training set.
- Chú ý phân biệt với `KFold`, vì các fold của `KFold` phân biệt nhau (*non-overlap*). Còn LPO sẽ lấy ra `p` bất kỳ cho đến khi không thể lấy được nữa, số lần test sẽ là $C(N,p)$ -> Rất hao tốn tài nguyên.

Ngoài ra còn có các **Group-based** Cross-validation iterators khá hay, có thể đọc thêm tại tài liệu tham khảo.

## sklearn.model_selection.cross_validate

```python
sklearn.model_selection.cross_validate(estimator, X, y, scoring, cv)
```

*Tham số*:
- `scoring`: Một `str` hoặc danh sách các `str` của [các tên chỉ báo đánh giá model](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-string-names). Việc thêm tiền tố `neg_` sẽ chuyển đổi trực tiếp sang score.
- `cv`: Số fold kỳ vọng để chia dataset (thường là `5`) hoặc Cross-validation iterators.

*Kết quả trả về*: Một `dict` chứa các key:
- `fit_time`: Thời gian train mỗi tuple.
- `score_time`: Thời gian predict mỗi tuple.
- `test_score`: Đánh giá (score) mỗi tuple dựa trên `scoring`, `test_score` càng cao thì model càng tốt.

VD:
```python
from sklearn import datasets, linear_model
from sklearn.model_selection import cross_validate
diabetes = datasets.load_diabetes()
X = diabetes.data[:150]
y = diabetes.target[:150]
lasso = linear_model.Lasso()

cv_results = cross_validate(lasso, X, y, cv=3)
cv_results['test_score']
```

Ngoài ra bạn có thể dùng `cross_val_score` 1 wrapper của `cross_validate` nhưng chỉ trả về `test_score`.

```python
sklearn.model_selection.cross_val_score(estimator, X, y, scoring, cv)
```
