
```insta-toc
---
title:
  name: Mục lục
  level: 1
  center: false
exclude: ""
style:
  listType: number
omit: []
levels:
  min: 1
  max: 6
---

# Mục lục

1. Tình huống
2. Một số phương pháp tự động hóa hiệu chỉnh tham số
    1. sklearn.modelselection.GridSearchCV
```

# Tình huống

*Hyperparameter* là các tham số của model.
- Xem danh sách tham số: Predictor`.get_params()`.
- Sửa tham số: Predictor `.set_params(par=...)`

Các parameter khác nhau kết hợp với dataset khác nhau sẽ cho ra error khác nhau. Một trong những công việc của data trainer là hiệu chỉnh hyperparameter sao cho error của model trên dataset đã biết là thấp nhất.

*VD*: Model `sklearn.linear_model.LogisticRegression` có tham số là `C`, ta sẽ dùng cross-validate để khảo sát độ chính xác khi `C` = `1`:

```python
cv_results = cross_validate(model, data, target)
scores = cv_results["test_score"]

print(
    "Accuracy score via cross-validation:\n"
    f"{scores.mean():.3f} ± {scores.std():.3f}"
)
```
```
Accuracy score via cross-validation:
0.800 ± 0.003
```

Thử lại với nhiều giá trị khác nhau của `C`:
```python
for C in [1e-3, 1e-2, 1e-1, 1, 10]:
    model.set_params(classifier__C=C)
    cv_results = cross_validate(model, data, target)
    scores = cv_results["test_score"]
    print(
        f"{scores.mean():.3f} ± {scores.std():.3f}"
    )
```
```
0.787 ± 0.002
0.799 ± 0.003
0.800 ± 0.003
0.800 ± 0.003
0.800 ± 0.003
```

Error đã thay đổi khi hyperparameter thay đổi.

# Một số phương pháp tự động hóa hiệu chỉnh tham số

## sklearn.model_selection.GridSearchCV

`GridSearchCV` có ý tưởng là:
1. Bạn cung cấp cho nó danh sách các hyperparameters cần xem xét (`param_grid`).
2. `GridSearchCV` sẽ kiểm tra tuần tự tất cả tổ hợp có thể, sau đó đưa ra tổ hợp tốt nhất.

**Nhược điểm**: Có thể bỏ sót các tổ hợp tốt hơn nếu chúng không được truyền vào grid.

Cú pháp:
```python
sklearn.model_selection.GridSearchCV(estimator, param_grid, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)
```

VD:
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    "classifier__learning_rate": (0.01, 0.1, 1, 10),  # 4 possible values
    "classifier__max_leaf_nodes": (3, 10, 30),  # 3 possible values
}  # 12 unique combinations

model_grid_search = GridSearchCV(model, param_grid=param_grid, n_jobs=2, cv=2)
model_grid_search.fit(data_train, target_train)

print(f"The best set of params: {model_grid_search.best_params_}")
```
```
The best set of params: {'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 30}
```

Xem chi tiết kết quả đánh giá:
```python
# Dataframe
cv_results = pd.DataFrame(model_grid_search.cv_results_)

# Build pivot table for clarity
pivoted_cv_results = cv_results.pivot_table(
    values="mean_test_score",
    index=["learning_rate"],
    columns=["max_leaf_nodes"],
)
```

## sklearn.model_selection.RandomizedSearchCV

`RandomizedSearchCV` là một sự cải tiến của `GridSearchCV`, thay vì chọn các tổ hợp cố định, nó chọn các tổ hợp ngẫu nhiên, qua đó khoanh vùng được vùng hyperparameter tối ưu.

![](https://inria.github.io/scikit-learn-mooc/_images/grid_vs_random_search.svg)

Cú pháp:
```python
sklearn.model_selection.RandomizedSearchCV(estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)
```

Trên thực tế, kể cả khi dùng `RandomizedSearchCV` cũng chưa chắc sẽ lấy được hyperparameter tốt nhất có thể nên người ta thường lặp lại nhiều lần để tìm hyperparameter tối ưu nhất, `n_iter` thường là `500`.

Chúng ta sẽ lấy một dãy số ngẫu nhiên từ `scipy.stats`:
```python
from scipy.stats import loguniform

# loguniform(a, b): Float ngẫu nhiên từ a đến b

# Loguniform cho int
class loguniform_int:
    def __init__(self, a, b):
        self._distribution = loguniform(a, b)
	
    def rvs(self, *args, **kwargs):
        return self._distribution.rvs(*args, **kwargs).astype(int)
```

VD:
```python
param_distributions = {
    "classifier__l2_regularization": loguniform(1e-6, 1e3),
    "classifier__learning_rate": loguniform(0.001, 10),
    "classifier__max_leaf_nodes": loguniform_int(2, 256),
    "classifier__min_samples_leaf": loguniform_int(1, 100),
    "classifier__max_bins": loguniform_int(2, 255),
}

model_random_search = RandomizedSearchCV(
    model,
    param_distributions=param_distributions,
    n_iter=10,
    cv=5,
    verbose=1,
)

model_random_search.fit(data_train, target_train)
```















