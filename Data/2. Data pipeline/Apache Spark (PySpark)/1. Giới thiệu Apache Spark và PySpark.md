
# Giới thiệu

**Spark**:
- Là một hệ thống tính toán mã nguồn mở phục vụ cho xử lý dữ liệu, bao gồm big data.
- Spark hỗ trợ:
	- Phân phối dữ liệu vào các cụm (*cluster distributing*), xử lý song song (*parallel*) và *catching* -> Giúp xử lý một lượng khổng lồ dữ liệu với hiệu năng cao.
	- Xử lý dữ liệu theo thời gian thực (*real-time processing*).
	- Có cơ chế sao lưu và phục hồi.
	- Tích hợp được nhiều nguồn dữ liệu và công nghệ xử lý dữ liệu khác nhau, kể cả *machine learning, graph processing và streaming analytics*.
	- Hỗ trợ nhiều loại ngôn ngữ lập trình (thông qua các *API*) như *Python, Java, Scala, R*.

Bài viết này sẽ nói về API của Python là **PySpark**.

# Cài đặt

**1 - Tải Java Development Kit (JDK)**:
1. Bạn có thể tải JDK [tại đây](https://www.oracle.com/java/technologies/downloads/#jdk24-windows). Riêng đối với Windows, hãy tải về file `x64 Installer`. Mặc định, folder của JDK 24.0.2 đặt tại `C:\Program Files\Java\jdk-24`.
2. Tạo biến môi trường:
	1. Vào cửa sổ `System properties`, tab `Advanced`, chọn `Environment Variables`.
	2. Tại cửa sổ `Environment Variables`, mục `System Variables` chọn `New...` để tạo biến mới. Hãy đặt `Variable name` là `JAVA_HOME`  và `Variable value` là đường dẫn folder JDK.
	3. Tại biến `PATH`, chọn `Edit...` để thêm giá trị `%JAVA_HOME%\bin`.

Để kiểm tra xem JDK đã được cài đặt chưa, bạn dùng lệnh:
```bash
java -version
```

**2 - Tải Apache Spark** [tại đây](https://spark.apache.org/downloads.html). Giả sử lưu folder này tại `C:\Users\Admin\Documents\Spark`.

**3 - Tải PySpark và JupyterLab**:

```sh
pip install pyspark
pip install findspark
pip install jupyterlab
```

**4 - Cài đặt các biến môi trường cho PySpark**:


| Field                        | Value                            |
| ---------------------------- | -------------------------------- |
| `SPARK_HOME`                 | `C:\Users\Admin\Documents\Spark` |
| `PYSPARK_DRIVER_PYTHON`      | `jupyter`                        |
| `PYSPARK_DRIVER_PYTHON_OPTS` | `lab`                            |
| `PYSPARK_PYTHON`             | `python`                         |

Chạy thử Jupyterlab:
```sh
jupyter-lab
```

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName('Test') \
    .config("spark.sql.execution.pyspark.udf.faulthandler.enabled", "true") \
    .config("spark.python.worker.faulthandler.enabled", "true") \
    .getOrCreate()

data = [('Alice', 25), ('Bob', 30), ('Charles', 35)]
df = spark.createDataFrame(data, ['Name', 'Age'])
df.show()
```




















