
```insta-toc
---
title:
  name: Mục lục
  level: 1
  center: false
exclude: ""
style:
  listType: number
omit: []
levels:
  min: 1
  max: 6
---

# Mục lục

1. Basic concepts
2. Task lifecycle
3. Airflow architecture
4. Cài đặt Airflow
    1. Môi trường ảo Python
    2. Docker compose
```

**Apache airflow** là:
- Một công cụ mã nguồn mở.
- **Orchestrator**: Lập lịch, thực thi, giám sát,... workflow một cách tự động.
- **Ngôn ngữ**: Python.

# Basic concepts

**Workflow** là một chuỗi các nhiệm vụ (**Task**) liên tiếp nhau. Trong Airflow, mỗi workflow được hiểu là 1 DAG.
**DAG (Directly acyclic graph)**:
- Là đồ thị có hướng và không có chu trình.
- Dùng để ký hiệu workflow.
- Cho biết thứ tự thực hiện các task.
- **Execution date**: Là thời điểm thực thi DAG.
- **DAG run**: Là 1 DAG đang được thực thi.


**Task**:
- Là một công việc, là đơn vị làm việc của workflow.
- Task có **dependencies** tức là task đó chỉ có thể được thực thi khi một hay một số task khác được thực thi xong. Các task đứng trước này được gọi là **upstream**.
- **Task instance**: Là 1 task đang được thực thi.


**Operator**:
- Là 1 lớp hành vi cụ thể của task.
- Mỗi task chỉ được sử dụng 1 operator để thực thi công việc của mình.
- Mỗi task là một đối tượng kế thừa operator (*implement*).

# Task lifecycle

Kể từ khi task được thực thi cho đến khi kết thúc nhiệm vụ thì trải qua nhiều trạng thái khác nhau:
1. `no_status`: Task mới được khởi tạo, chưa làm gì cả.
2. **Scheduler**: Tạo ra 1 task instance, lúc này task có 4 loại trạng thái:
	1. `scheduled`: Task đã được lập lịch để thực thi.
	2. `removed`: Task đã bị xóa.
	3. `upstream_failed`: Có upstream đã thất bại và task sẽ không được thực thi.
	4. `skipped`: Task đã bị bỏ qua, không thực thi.
3. **Executer**: Nếu task có trạng thái `scheduled` và đã đến thời điểm thực thi, executer sẽ đưa task vào queue để chuẩn bị thực thi, task có trạng thái `queued`.
4. **Worker**: Nếu có thể thực thi task trong queue, worker sẽ thực thi nó, task có trạng thái `running`.
5. Sau khi thực thi, có 3 loại trạng thái:
	1. `success`: Task đã hoàn thành công việc mà không có lỗi.
	2. `failed`: Đã có lỗi xảy ra.
	3. `shutdown`: Task bị đóng khi đang thực thi.
	4. `up_for_reschedule`: Task bị tạm ngưng, đợi để thực thi lại (`scheduled`).
6. Khi task bị `failed` hoặc `shutdown`, nó được gắn trạng thái `up_for_retry`: Đợi để thực thi lại (`scheduled`) (*nếu có thể*).

| Task lifecycle          | Một lifecycle hoàn hảo        |
| ----------------------- | ----------------------------- |
| ![](task-lifecycle.png) | ![](happy-task-lifecycle.png) |

# Airflow architecture

**Một số service của Airflow (được khai báo rõ trong `docker-compose.yaml`)**:
- **`airflow-init`**: Khởi tạo Airflow. Các thông tin về Airflow như *số phiên bản, số liệu thống kê, lịch trình, ...* được lưu trong **Metadata database** (*Postgres*) và khởi tạo bởi `airflow-init`.
-  **`airflow-apiserver` / `airflow-webserver`**: API và GUI của Airflow.
- **`airflow-scheduler`**: Lập lịch cho DAG, điều phối thực thi DAG hoặc trực tiếp thực thi DAG nếu executor là local.
- **`AIRFLOW__CORE__EXECUTOR`**: Xử lý quy trình thực thi các task. Có 1 số loại excutor là:
	- `CeleryExecutor`: Giao mỗi task cho mỗi worker xử lý, giảm thiểu rủi ro, thích hợp cho các task lớn.
	- `LocalExecuter`: Các task được thực thi dưới dạng *sub-processes (thực thi song song và dùng chung 1 tài nguyên hệ thống) -> dễ nghẽn*, không cần set-up gì nhiều, thích hợp để chạy thử nghiệm các task khá nhỏ,

![](https://images.viblo.asia/e2d80240-05d3-4d64-a82d-3f7a37dd914a.png)

Ngoài ra còn có:
- **`airflow-dag-processor`**: Biên dịch mã DAG do người dùng soạn thảo thành mã Python thuần.
- **`airflow-triggerer`**: Xử lý các task chờ IO như sensor.


# Cài đặt Airflow

## Môi trường ảo Python

Tham khảo:
- [Github / Apache Airflow / INSTALLING.md](https://github.com/apache/airflow/blob/main/INSTALLING.md).

Không khuyến khích tạo môi trường ảo vì Airflow tương thích với *Linux* nhiều hơn, rất khó set-up trên các OS khác.

## Docker compose

(*Hướng dẫn dành cho Windows OS*)

Tài liệu tham khảo:
- [Airflow Apache / Docker compose](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html).

**1 - Mở Docker Destop**.

**2 - Tải file [`docker-compose.yaml`](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#:~:text=you%20should%20fetch-,docker%2Dcompose.yaml,-.)** tại Airflow docs và đưa vào project của bạn.
- Chú ý rằng Airflow là một chương trình rất nặng, bạn nên bỏ bớt các cấu hình không cần thiết như `CeleryWorker`, `redis`,...
- Tắt `AIRFLOW__CORE__LOAD__EXAMPLES` là `'false'` để xóa các ví dụ có sẵn.

Cấu hình tham khảo:
- [Github / Coder2j / airflow-docker](https://github.com/coder2j/airflow-docker).
- [Youtube / Coder2j / Airflow Tutorial for Beginners - Full Course in 2 Hours 2022](https://www.youtube.com/watch?v=K9AnJ9_ZAXE&list=PLwFJcsJ61oujAqYpMp1kdUBcPG0sE0QMT&index=1&t=644s).

**3 - Khởi tạo Airflow user**:
```sh
mkdir dags, logs, plugins, config
```

**4 - Tạo file `.env` có nội dung là**: `AIRFLOW_UID=50000`.

**5 - Khởi tạo database**:
```sh
docker compose up airflow-init
```
Quá trình tải các images kết thúc khi bạn trông thấy thông báo `airflow-init-1 exited with code 0`.

**6 - Chạy Airflow**:
```sh
docker compose up
```

Để kiểm tra trạng thái các container, bạn mở Shell thứ 2 và dùng lệnh:
```sh
docker ps
```
Hãy đảm bảo các container đều `healthy`.

Ngay sau đó, bạn có thể dùng web browser để truy cập Airflow GUI. Mặc định, Airflow sẽ chạy ở `localhost:8080`.

**7 - Tắt Airflow**:
- Dùng tổ hợp `Ctrl` `C` để gửi tín hiệu ngắt.
- Chú ý khi tắt thì mọi các workflow sẽ ngưng hoạt động, không thể chạy online.
