
```insta-toc
---
title:
  name: Mục lục
  level: 1
  center: false
exclude: ""
style:
  listType: number
omit: []
levels:
  min: 1
  max: 6
---

# Mục lục

1. Các khái niệm cơ sở
    1. Quản lý bộ nhớ
    2. Mục tiêu
    3. Yêu cầu đối với việc quản lý bộ nhớ
2. Các kiểu địa chỉ nhớ
    1. Các kiểu địa chỉ nhớ
    2. Chuyển đổi địa chỉ
    3. Dynamic linking
    4. Dynamic loading
3. Mô hình quản lý bộ nhớ
    1. Phân mảnh (Fragmentation)
    2. Phân chia (Partitioning)
    3. Phân trang (Paging)
4. Bảo vệ bộ nhớ
5. Hoán vị (Swapping)
```

# Các khái niệm cơ sở

## Quản lý bộ nhớ

**Quản lý bộ nhớ** là công việc của OS với sự hỗ trợ của phần cứng nhằm *phân phối, sắp xếp* các process trong bộ nhớ sao cho hiệu quả.

## Mục tiêu

Nạp càng nhiều process vào bộ nhớ càng tốt (*gia tăng mức độ đa chương*).

Ở hầu hết hệ thống, **kernel sẽ chiếm một phần cố định của bộ nhớ**; phần còn lại phân phối cho các process.

## Yêu cầu đối với việc quản lý bộ nhớ

- **Cấp phát** bộ nhớ cho các process.
- **Tái định vị** (Relocation) khi swapping (*chuyền bộ nhớ qua nhiều process truy cập*).
- **Bảo vệ** bộ nhớ khỏi các truy cập bất hợp pháp.
- **Chia sẻ** bộ nhớ cho các process dùng chung.
- **Kết nối** địa chỉ luận lý của user vào địa chỉ thực.

# Các kiểu địa chỉ nhớ

## Các kiểu địa chỉ nhớ


| Địa chỉ vật lý                                                                                                     | Địa chỉ luân lý                                                                                                                    |
| ------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------- |
| **Địa chỉ vật lý, Địa chỉ thực (Physical address)**<br>Là vị trí thực trong bộ nhớ chính.                          | **Địa chỉ luận lý, Địa chỉ ảo (Loical address, Virtual address)**<br>Là vị trí diễn tả bên trong 1 chương trình.                   |
| **Địa chỉ tuyệt đối (Absolute address)**<br>Là một phần của địa chỉ vật lý, được gắn cố định cho mỗi chương trình. | **Địa chỉ tương đối (Relative address)**<br>Là một loại địa chỉ luân lý, dùng để relocation, dùng địa chỉ chương trình làm mốc đo. |

**Biểu diễn địa chỉ nhớ**:
- Trong *source code*: **Symbolic** (các biến, hằng, pointer,...).
- Trong *compile time*: Thường là **địa chỉ khả tái định vị (tương đối)**.

## Chuyển đổi địa chỉ

**Chuyển đổi địa chỉ**: Là quá trình ánh xạ một địa chỉ từ không gian địa chỉ này sang không gian địa chỉ khác.

**Địa chỉ lệnh và dữ liệu được chuyển đổi thành địa chỉ thực** xảy ra tại 3 thời điểm:
1. **Compile time**: Nếu biết trước địa chỉ bộ nhớ của chương trình thì có thể kết gán địa chỉ tuyệt đối lúc biên dịch. Khuyết điểm: *Phải biên dịch lại* nếu thay đổi địa chỉ nạp chương trình.
2. **Load time**: Loader phải chuyển đổi *địa chỉ khả tái định vị thành địa chỉ thực* dựa trên một địa chỉ nền.
3. **Nạp chương trình**: Tính toán địa chỉ thực, phải reload nếu địa chỉ nền thay đổi.

## Dynamic linking

Dynamic linking là kỹ thuật mà **việc liên kết với các thư viện ngoài (External module)** (`.dll` - Windows / `.so` - Linux) **trong runtime** (*đã tạo xong Loaded module*), chứ không phải trong compile time hay build time.

Mỗi Loaded module chứa các **stub**. Stub là một đoạn mã nhỏ tham chiếu (*reffer*) đến **routine** (đoạn mã) của các external module.
- Trong runtime, khi stub được thực thi lần đầu, stub thực hiện 3 hành vi sau:
	1. Nạp routine vào bộ nhớ.
	2. Tự thay thế chính nó bằng địa chỉ của routine.
	3. Thực thi routine.
-  Ở các lần gọi sau, routine được thực thi trực tiếp chứ không cần thông qua stub.

Stub cần sự hỗ trợ của OS (như kiểm tra xem routine đã được nạp vào bộ nhớ chưa).

## Dynamic loading

Dynamic loading là kỹ thuật mà một đoạn mã (module/routine) **chỉ được nạp vào bộ nhớ khi cần**, không cần nạp toàn chương trình ngay từ đầu.

OS có nhiệm vụ **cung cấp các thủ tục, thư viện** để dev thiết kế dynamic loading.

**Ưu điểm**:
- Tăng độ hiệu dụng của bộ nhớ bởi vì các thủ tục không được gọi đến sẽ không chiếm chỗ trong bộ nhớ.
- Hiệu quả trong trường hợp tồn tại khối lượng lớn mã chương trình có tần suất sử dụng thấp, không được sử dụng thường xuyên (ví dụ các thủ tục xử lý lỗi).

# Mô hình quản lý bộ nhớ

Trong chương này, mô hình quản lý bộ nhớ là một mô hình đơn giản, *không có bộ nhớ ảo*. Một process phải được nạp hoàn toàn vào bộ nhớ thì mới được thực thi.

Có 4 cơ chế:
1. Phân chia cố định (Fixed partitioning).
2. Phân chia động (Dynamic partitioning).
3. Phân trang đơn giản (simple paging).
4. Phân đoạn đơn giản (simple segmentation).

## Phân mảnh (Fragmentation)

**Phân mảnh** là hiện tượng **bộ nhớ bị chia cắt thành nhiều phần nhỏ**, khiến việc sử dụng bộ nhớ *không hiệu quả*.

**Phân mảnh ngoại (External fragmentation)**
- **Vùng nhớ được cấp phát ==nhỏ hơn== so với process yêu cầu** -> Vùng nhớ dư ra bị rời rạc thành từng mảnh nhỏ.
- Khắc phục: Cơ chế Kết khối (*Compaction*) để gom lại thành vùng nhớ liên tục.

**Phân mảnh nội (Internal fragmentation)**:
- **Vùng nhớ được cấp phát ==lớn hơn== so với process yêu cầu** -> Bị thừa vùng nhớ.
- Thường xảy ra khi bộ nhớ thực được chia thành các khối kích thước cố định (*Fixed-sized block*) và các process được cấp phát theo đơn vị khối (phân trang - paging).

## Phân chia (Partitioning)

**Phân chia**: Là chia bộ nhớ chính thành nhiều phần (*Partition*), dùng cho cấp phát *liên tục*.

1. **Phân chia cố định (Fixed partitioning)**:
	- Các partition có kích thước cố định, bằng nhau hoặc khác nhau -> Dễ bị **phân mảnh nội**.
	- Khi process được xét để cấp bộ nhớ:
		- Process có kích thước $\leq$ partition -> Nạp process vào.
		- Process có kích thước $>$ partition -> Dùng *Overlay*.
		- Process được nạp nhưng vùng nhớ đang bận -> Đưa process đó sang bộ nhớ phụ (*queue*) để đợi. Có thể có 1 queue hoặc nhiều queue.

2. **Phân chia động (Dynamic partitioning)**:
	- Các partition có thể có kích thước khác nhau, mỗi process được cấp chính xác 1 vùng nhớ cần thiết -> Dễ bị **phân mảnh ngoại**.
	- **Placement**: Là kỹ thuật quyết định *cấp phát khối bộ nhớ nào cho process*, sao cho giảm Compaction nhất có thể. Có 4 loại:
		1. **Best-fit**: Chọn khối trống **nhỏ nhất**.
		2. **Worst-fit**: Chọn khối trống **lớn nhất**.
		3. **First-fit**: Chọn khối trống **đầu tiên** có thể cấp phát.
		4. **Next-fit**: Chọn khối trống **đầu tiên** có thể cấp phát **tính từ vị trí khối được cấp phát cuối cùng**.

>[!note] Chú ý phân biệt với các kỹ thuật page-fault service routine (PFSR) (Demand paging) của virtual memory
>- **FIFO (First-in First-out)**: Thay thế trang **đã được dùng** sớm nhất.
>- **LRU (Least Recently Used)**: Thay thế trang **hiện chưa dùng** lâu nhất.
>- **OPT (Optimal)**: Thay thế trang **dự định** sẽ dùng lâu nhất hoặc không dùng nữa.

## Phân trang (Paging)

![](paging.png)

**Phân trang (Paging)**: Là chia bộ nhớ chính thành nhiều phần, dùng cho cấp phát **không liên tục**.
- **Trong bộ nhớ vật lý**: Chia thành các **frame**, mỗi frame rộng $2^n$ byte.
- **Trong bộ nhớ luận lý**: Chia thành các **page**, có kích thước như frame.

Một process cần $N$ page thì sẽ cần được cấp $N$ frame tương ứng. Page và frame được ánh xạ thông qua **Bảng phân trang (Page table)**.
-> Dễ *phân mảnh nội*.

Mỗi process được OS cấp một page table, gồm 2 thanh ghi (*Thanh ghi kết hợp* - Associative / *Translation look-aside buffers* - TLBs):
- **Page-table base register (PTBR)**: Địa chỉ page table.
- **Page-table length register (PTLR)**: Kích thước của page table, có thể dùng cho cơ chế *bảo vệ bộ nhớ*.
Như vậy, cứ mỗi một thao tác truy cập lệnh / dữ liệu thì cần **2 lần truy cập bộ nhớ chính**:
- Lần 1 cho page table.
- Lần 2 cho lệnh / dữ liệu.

>[!note]
>Mỗi process có thể được cấp 1 hay vài *page table*.

---
**Xây dựng page table**:

Mỗi địa chỉ ảo đều có 2 phần:
- **Độ dời trang `d` (Page offset)**: Là $n$ bit phải cùng của địa chỉ.
- **Chỉ số trang `p` (Page number)**: Là các bit còn lại.

Thường ký hiệu là `(p, d)`.

Gọi:
- Kích thước không gian địa chỉ ảo = $2^m$ B.
- Kích thước mỗi frame / page = $2^n$ B => Offset = $n$ bit.

Như vậy Số lượng page (**Entry**) sẽ là $\frac{2^m}{2^n}=2^{m-n}$.

---
**Effective access time (EAT) - Thời gian truy xuất hiệu dụng**:

Gọi:
- $t_{lookup}$: Thời gian tìm số trang trong Page table (TLBs) (Associate lookup).
- $t_{access}$: Thời gian chu kỳ truy xuất bộ nhớ.
- $h$: Tỷ lệ số lần tìm thấy chỉ số trang (hit).

Khi đó:
$$
\begin{align}
\text{EAT}&=\boxed{(t_{lookup}+t_{access})h+(t_{lookup}+2.t_{access})(1-h)}\\
&=(2-h)t_{access}+t_{lookup}
\end{align}
$$
Trong đó:
- $t_{lookup}+t_{access}$: Thời gian khi **tìm thấy page number** trong page table.
- $t_{TLB}+2t_{access}$: Thời gian khi không tìm thấy page number, phải truy cập page table **lấy page number** (1 lần) rồi **truy cập lại bộ nhớ lấy frame number** (1 lần nữa).

# Bảo vệ bộ nhớ

Trong *page table*, có 2 loại bit để phục vụ cho bảo vệ bộ nhớ:
- **Bit bảo vệ (Protection bits)**: Gồm 3 trạng thái là *Read-only, Read-Write, Execute-only*.
- **Bit hợp lệ (Valid/Invalid bits)**: Cho biết tính hợp lệ của page (nếu page đang thuộc process).

# Hoán vị (Swapping)

Khi **bộ nhớ của 1 process** bị block, bộ nhớ của nó tạm thời bị swap ra khỏi bộ nhớ chính (**Swap out / Roll out**) và lưu trên một hệ thống lưu trữ phụ. Sau đó, bộ nhớ đó có thể được giải phóng (**Swap in / Roll in**) để tprocess sử dụng.

>[!caution]
>- Thuật ngữ *Swap in, Swap out* là dùng trong **Robin Round**.
>- Thuật ngữ *Roll in, Roll out* là dùng trong **Priority-based scheduling**.
