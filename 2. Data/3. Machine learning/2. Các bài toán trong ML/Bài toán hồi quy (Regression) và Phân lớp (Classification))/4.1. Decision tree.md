
**Tài liệu tham khảo**:
- https://scikit-learn.org/stable/modules/tree.html.
- https://machinelearningcoban.com/tabml_book/ch_model/decision_tree.html.

# Giới thiệu

**Decision tree** là một mô hình có thể áp dụng cho cả bài toán regression và classification.

**Mục tiêu**: Nhận biết kết quả của một bài toán có 2 kết quả. Mô hình bài toán là một *cây nhị phân*.

**Ưu điểm**:
- Dễ hiểu, trực quan.
- Không yêu cầu quá nhiều ở khâu chuẩn bị dữ liệu. Decision tree có thể giải quyết cả các dữ liệu bị thiếu. Có thể xử lý nhiều kiểu dữ liệu khác nhau (*numerical, categorical,...*).
- Độ phức tạp nhỏ ($O(\log{n})$), hiệu năng cao.

**Nhược điểm**:
- Decision tree có thể bị phình to quá mức cần thiết (*Overfiting*), cũng có thể quá đơn giản (*Undefiting*). Giải pháp được đưa ra là **pruning**: giới hạn chiều cao cây, và các giải pháp giảm overfitting và underfiting.
- Nhạy cảm với dữ liệu. Nhất là các dataset bị thiên lệch.
- Đồ thị decision tree không liên tục hoặc trơn tru, nên khó ngoại suy (*extrapolation*).

**VD**: *Titanic dataset*: Dựa vào thông tin của hành khách để quyết định xem hành khách đó sống hay chết:

![](https://machinelearningcoban.com/tabml_book/_images/titanic.png)

# Sử dụng

## Classifier

```python
from sklearn import tree
X = [[0, 0], [1, 1]]
Y = [0, 1]
clf = tree.DecisionTreeClassifier()
clf = clf.fit(X, Y)

clf.predict([[2., 2.]])
```
```sh
array([1])
```

Logic của cây trong trường hợp này:
```sh
if x <= 0.5:
    predict 0
else:
    predict 1
```

Có thể thấy cây không ngoại suy được bên ngoài `0` và `1`.

Lấy về xác suất xảy ra các label:
```python
clf.predict_proba([[2., 2.]])
```
```sh
array([[0., 1.]])
```

## Regession

```python
from sklearn import tree
X = [[0, 0], [2, 2]]
y = [0.5, 2.5]
clf = tree.DecisionTreeRegressor()
clf = clf.fit(X, y)
clf.predict([[1, 1]])
```
```sh
array([0.5])
```














