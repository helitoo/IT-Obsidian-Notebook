
**Tài liệu tham khảo**:
- https://scikit-learn.org/stable/modules/cross_validation.html.
- https://www.kaggle.com/learn/intermediate-machine-learning.
- https://inria.github.io/scikit-learn-mooc/overfit/overfit_module_intro.html.
- Machine Learning cơ bản, Vũ Hữu Tiệp, 2018.

# Tình huống

- **Overfiting**: Là hiện tượng model quá khớp với training set (error cực thấp) trong khi đạt error cao khi gặp phải những dữ liệu nằm ngoài training set. Các model này thường có một lượng lớn tham số, tức là model rất phức tạp.
- **Underfiting**: Là trường hợp ngược lại với overfitting, model cho ra kết quả dường như chẳng khớp gì với training set.

Cả overfiting và underfiting đều không phải hiện tượng tốt tốt.

>[!quote]
>**Error** quá nhỏ hoặc quá lớn **đều là vấn đề**.

3 biểu đồ dưới đây thể hiện bài toán *Regression* với mô hình tương ứng với 3 bậc khác nhau:
- *Mô hình bậc 4*: Khớp nhất so với mô hình kỳ vọng (true function).
- *Mô hình bậc 15*: Overfiting, khớp hoàn toàn với training set và sai lệch hẳn so với true function.
- *Mô hình bậc 1*: Underfiting, dường như không khớp gì với training set và sai lệch hẳn so với true function.

![](https://scikit-learn.org/stable/_images/sphx_glr_plot_underfitting_overfitting_001.png)

Hiện tượng overfit và underfit dẫn đến 2 hiện tượng khác:
- **Variance**: Xảy ra khi overfit. Nếu model quá fit với training set thì khi tiếp cận với dataset mới, model sẽ phán đoán sai, nhưng nhìn chung thì **ở mỗi dataset thì model phán đoán gần như khác hẳn với các dataset khác**.
- **Bias**: Xảy ra khi Underfit. Nếu model không catch được training set thì khi tiếp cận với dataset mới, model sẽ phán đoán sai, nhưng nhìn chung thì **ở mỗi dataset thì model phán đoán gần giống như nhau**.

2 biểu đồ bên dưới thể hiện 2 hiện tượng variance và bias, với mỗi điểm khác nhau trên hình tròn đại diện cho 1 dataset khác nhau, rơi vào các mốc error khác nhau (*tại tâm thì error = 0*).

| ![](variance.png) | ![](bias.png) |
| ----------------- | ------------- |

# Nhận biết overfiting / underfiting

## Độ phức tạp của model

Gọi:
- **Training error**: Sai số trên training set.
- **Testing error**: Sai số trên testing set (*model không được training bởi testing set*).

- **Overfit**: Training error rất thấp nhưng testing error rất cao.
- **Underfit**: Training error và testing error đều cao.

>[!quote]
>Model đạt mức tốt nhất tại vị trí mà **training error và testing error đều thấp**.

![](training-testing-error.png)

## Kích thước dataset

Kích thước dataset càng cao thì **training error và testing error sẽ cùng hội tụ về một mức error cố định**, không thể thay đổi thêm dù có tăng kích thước dataset như thế nào đi nữa.

Mốc error này gọi là **Bayes error rate**. Bayes error rate không thể là $0$ vì các lý do như noises, limiting sample size,...

![](varying-sample-size.png)

## Đặc thù của model

Các model khác nhau cho ra kết quả khác nhau, nếu không hiểu rõ về bản chất của model, ta có thể nhầm lẫn rằng model này overfit hoặc underfit hơn model kia.

VD 2 biểu đồ dưới thể hiện polynomial model (trông khá fit với dữ liệu) và decision tree model (có vẻ như overfit).

![](differences-model-families.png)

# Khảo sát chất lượng model bằng Cross-validation estimation

Nhìn chung, các phương pháp đánh giá mô hình đều dựa trên **training error** và **testing error**.

**Cross-validation** là một phương pháp đánh giá mô hình dựa trên nguyên lý đó, nhưng thay vì chỉ chia dữ liệu một lần, cross-validation **chia dữ liệu thành nhiều phần (_fold_) và đánh giá mô hình nhiều lần**.

Có nhiều cách thực hiện cross-validation, nhưng nhìn chung đều trải qua các bước sau:
1. \[*Optional*] Xáo trộn ngẫu nhiên toàn bộ dataset (shuffle), nhằm đảm bảo các fold có phân phối dữ liệu đại diện.
2. **Chia dataset thành $k$ fold không chồng lặp**, kích thước xấp xỉ nhau.
3. **Lặp $k$ lần** quá trình training và đánh giá:
    - Mỗi lần chọn **1 fold làm testing set**.
    - $k-1$ fold còn lại được gộp lại làm **training set**.
4. Với mỗi cặp testing - training set như trên, training và scoring model như bình thường. Kết quả tổng thể có thể lấy trung bình.

Sklearn cung cấp phương thức `sklearn.model_selection.cross_val_score` để scoring model qua từng testing - training set.

Có rất nhiều thuật toán để chia fold, thuật toán mặc định của `cross_val_score` là `KFolds`: Chia dataset thành `cv` fold và không xáo trộn.

![](https://storage.googleapis.com/kaggle-media/learn/images/9k60cVA.png)

**VD**: Dùng cross-validation đơn thuần:
```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.model_selection import cross_val_score

my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),
                              ('model', RandomForestRegressor(n_estimators=50,
                                                              random_state=0))
                             ])

# Multiply by -1 since sklearn calculates *negative* MAE
scores = -1 * cross_val_score(my_pipeline, X, y,
                              cv=5, # 5 folds
                              scoring='neg_mean_absolute_error')

# Show the answer
print("MAE scores:\n", scores)
print("\nAverage MAE score (across experiments):\n", scores.mean())
```
```sh
MAE scores:
[301628.7893587  303164.4782723  287298.331666   236061.84754543, 260383.45111427]

Average MAE score (across experiments):
277707.3795913405
```

**VD**: Dùng cross-validation để tìm hyperparameter `n_estimators` phù hợp cho model RandomForest:

```python
def get_score(n_estimators):
    my_pipeline = Pipeline(steps=[
        ('preprocessor', SimpleImputer()),
        ('model', RandomForestRegressor(n_estimators, random_state=0))
    ])

    scores = -1 * cross_val_score(
        my_pipeline,
        X,
        y,
        cv=3,
        scoring='neg_mean_absolute_error'
    )
        
    return scores.mean()
    
results = {}
for n_estimators in range(50, 450, 50): # 50, 100, 150, ..., 300, 350, 400
    results[n_estimators] = get_score(n_estimators)

plt.plot(list(results.keys()), list(results.values()))
plt.show()
```

![[hyperparameter-tunning-randomforest.png]]

Tại `n_estimators` = `200` thì MAE tối ưu nhất.














